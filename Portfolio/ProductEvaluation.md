# Product Evaluation

Our product has been constantly evaluated at regular intervals at throughout the project. At the start of the project, it was decided that we would use agile development practices. Every few weeks, we would work on new features to push for the next update. Once we had enough new features, we would hold a meeting to discuss them as well as what we would work on in the future. Our clients were happy for us to lead these sessions, and we came prepared with what we had updated and suggestions for either personalization changes to these or future upgrades. This gave a healthy balance between us offering suggestions for what we could include, and the clients being able to pick and choose where development time was spent. 

### Why we didn't use written feedback

It became clear early on that everyone was more comfortable with verbal feedback than written and there are a few reasons for this. The first was that we found it was much easier to get meaning across in a face to face meeting. This has come in useful many times when we have been able to question each other's answers and therefore explain an idea in a way we all understand. Our clients also only have a surface level knowledge of software development and therefore it is far easier to quickly list through design ideas and their viability when we answer them in real time.  
There would also have been some advantages to written feedback. In a discussion it is easy to go off on a tangent and perhaps visit one topic too much while giving less attention to another. It is far easer during the slower pace of a written assessment to give a more balanced judgement. It is also less impacted by bias from our own group. If we are strongly praising a feature we built in, it could lead the client to agree with us, even if the do not share our opinion. The group dynamic of the meeting could very easily lead to a situation like this.  
We did decide in the end to stick with verbal group evaluations as we saw them as a better overall method for the reasons provided.

### Our evaluation process
Our general process had a few defined steps.  
Initially, we would talk about what we were, and possibly were not, able to achieve in the last sprint. This gave us a good baseline for what topics we should stick to over the session.  
Next, we would give our clients a guided hands on with the application where we could go in depth with our explanation of subtle elements.  
The client would then be given free reign to explore anything they wanted. This stage was key to finding out what our clients instinctively cared about in their product. Being able to watch and see where they regularly go, and what they immediately try to do, gave us valuable information on what we should develop. This was just as beneficial to the clients as us, because direct contact can stir up new ideas quickly.  
Finally, we would collect all our ideas and decide on what we should work on in the future. Our clients were always happy for us to lead this discussion and in particular come up with features not present in the old manual system. They did however always have the final say on what we worked on. We documented the client's thoughts just as simple notes throughout the whole session and at the end wrote a plan of what we would do next. This came in the form of tasks and bug reports in Jira that we created there and then. We could therefore work with the clients in creating our task whilst ensuring we are correctly understanding their intentions.